{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#Load data\n",
    "pre_cleaned_df = pd.read_csv('UC_Irvine_ML_datasets.csv')\n",
    "\n",
    "#inspect dataframe information\n",
    "pre_cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select only relevant columns\n",
    "pre_cleaned_df = pre_cleaned_df[[\n",
    "                                'header', 'DataSetCharacteristics', 'NumberofInstances', 'Area',\n",
    "                                'AttributeCharacteristics', 'NumberofAttributes', 'DateDonated',\n",
    "                                'AssociatedTasks','MissingValues', 'NumberofWebHits'\n",
    "                                ]]\n",
    "pre_cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import data_cleaning\n",
    "from data_cleaning import get_Univ_Loc_match\n",
    "\n",
    "#fill na values\n",
    "cleandata = data_cleaning.fillna(pre_cleaned_df)\n",
    "\n",
    "#de-normalize categorical columns into indicator dummy variables\n",
    "cleandata = data_cleaning.create_characteristics_columns(cleandata)\n",
    "cleandata = data_cleaning.create_attribute_columns(cleandata)\n",
    "cleandata = data_cleaning.create_tasks_columns(cleandata)\n",
    "\n",
    "#convert 'DateDonated' to real date value\n",
    "cleandata = data_cleaning.convert_to_datetime(cleandata)\n",
    "\n",
    "#drop all records with NA values\n",
    "cleanest_data = data_cleaning.final_na_drop(cleandata)\n",
    "\n",
    "\n",
    "cleanest_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#re-import the file \n",
    "src_df = pd.read_csv('cleanest_data.csv', encoding=\"latin-1\")\n",
    "\n",
    "#add lookup-text-search institution / location values to src\n",
    "src_df['source_institution_places'] = src_df['Source'].apply(get_Univ_Loc_match)\n",
    "\n",
    "#add year from DateDonated column\n",
    "src_df['YearAdded'] = src_df['DateDonated'].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True).year)\n",
    "#additionally add the age of the dataset, subtracted from 2020\n",
    "src_df['DatasetAge'] = src_df['YearAdded'].apply(lambda x: 2020-x)\n",
    "\n",
    "#add column multiply rows*columns to get number of cells in dataset\n",
    "def calc_num_cells(x):\n",
    "    out = x['NumberofInstances'] * x['NumberofAttributes']\n",
    "    return out\n",
    "src_df['DatapointCount'] = src_df.apply(calc_num_cells, axis=1)\n",
    "\n",
    "src_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geograpgic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def worldmap(df):\n",
    "    pyo.init_notebook_mode()\n",
    "    #'multivariate_data', 'time_series_data', 'data_generator_data', 'domain_theory_data', 'image_data', 'relational_data', 'sequential_data', 'spatial_data', 'univariate_data', 'spatio_temporal_data', 'text_data', 'transactional_data'\n",
    "    df = df[df['source_institution_places'].str.len() > 6]\n",
    "    datasetcount = len(df.index)\n",
    "    srclist = df[['source_institution_places']].values.tolist()\n",
    "    countrylist = []\n",
    "    for x in srclist:\n",
    "        if x != [np.nan]:\n",
    "            x = x[0].split(\"|\")\n",
    "            for xsub in x:\n",
    "                xsub = xsub.split(\";\")\n",
    "                countrylist.append(xsub)\n",
    "    df = pd.DataFrame(countrylist, columns = ['University', 'City', 'Country', 'CODE',])\n",
    "    \n",
    "    df = df.groupby(['Country', 'CODE'],as_index=False).size().reset_index()\n",
    "    df.columns = [*df.columns[:-1], 'Dataset Count']\n",
    "\n",
    "    #merge dataframes\n",
    "    df = df.merge(country_codes, how='right', on=['CODE'])\n",
    "    df['Country'] = df['Country_y']\n",
    "    df = df.drop(['Country_x', 'Country_y'], axis=1)\n",
    "    df = df[df.Country != 'Antarctica']\n",
    "    df=df.fillna(0)\n",
    "    df['hover_text'] = 'Country: ' + df['Country'] +  '\\nNumber of Datasets: ' + df['Dataset Count'].astype(str)\n",
    "\n",
    "    def dataset_count_calc(x):\n",
    "        #maxval = 15\n",
    "        out = (float(x) * 100.00) / float(datasetcount)\n",
    "        #out = maxval if out > maxval else out\n",
    "        return out\n",
    "\n",
    "    df['Dataset Count Pct'] = df['Dataset Count'].apply(dataset_count_calc)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Choropleth(\n",
    "        locations = df['CODE'],\n",
    "        z = df['Dataset Count Pct'],\n",
    "        hovertext = df['hover_text'],\n",
    "        colorscale = 'Blues',\n",
    "        autocolorscale=False,\n",
    "        reversescale=False,\n",
    "        marker_line_color='darkgray',\n",
    "        marker_line_width=0.5,\n",
    "        colorbar_title = 'Sourced % Datasets',\n",
    "        zmin=0,\n",
    "        zmax=10\n",
    "    ))  \n",
    "    fig.update_layout(\n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "        title_text='UC Irvine ML Dataset Analysis',\n",
    "        geo=dict(\n",
    "            showframe=False,\n",
    "            showcoastlines=False,\n",
    "            projection_type='mercator'\n",
    "        ),\n",
    "        annotations = [dict(\n",
    "            x=0.55,\n",
    "            y=0.1,\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text='Source: <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">\\\n",
    "                UCI Machine Learning Repository</a>',\n",
    "            showarrow = False\n",
    "        )]\n",
    "    )\n",
    "    #print(df)\n",
    "    #fig.write_html(basedir + \"viz_worldmap_sourced_pct_datasets.html\")\n",
    "    return fig\n",
    "\n",
    "country_codes = pd.read_csv(\"all_country_codes.csv\")\n",
    "src_df = pd.read_csv('cleanest_data_augmented.csv', encoding=\"latin-1\")\n",
    "\n",
    "worldmap(src_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('viz': conda)",
   "language": "python",
   "name": "python38364bitvizconda5a66871c45674ee1835bf348f09a8e48"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
