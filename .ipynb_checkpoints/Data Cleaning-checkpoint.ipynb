{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data scraped from UC Irvine ML Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pandas package and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "pre_cleaned_df = pd.read_csv('UC_Irvine_ML_datasets.csv')\n",
    "\n",
    "#select only relevant columns\n",
    "pre_cleaned_df = pre_cleaned_df[[\n",
    "                                'header', 'DataSetCharacteristics', 'NumberofInstances', 'Area',\n",
    "                                'AttributeCharacteristics', 'NumberofAttributes', 'DateDonated',\n",
    "                                'AssociatedTasks','MissingValues', 'NumberofWebHits'\n",
    "                                ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN in columns\n",
    "pre_cleaned_df['MissingValues'] = pre_cleaned_df['MissingValues'].fillna('No')\n",
    "pre_cleaned_df['NumberofInstances'] = pre_cleaned_df['NumberofInstances'].fillna(0)\n",
    "pre_cleaned_df['NumberofAttributes'] = pre_cleaned_df['NumberofAttributes'].fillna(0)\n",
    "pre_cleaned_df['AttributeCharacteristics'] = pre_cleaned_df['AttributeCharacteristics'].fillna('Other')\n",
    "pre_cleaned_df['AssociatedTasks'] = pre_cleaned_df['AssociatedTasks'].fillna('Other')\n",
    "pre_cleaned_df['Area'] = pre_cleaned_df['Area'].fillna('Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column for each data characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force data set characteristics column to string data type\n",
    "pre_cleaned_df['DataSetCharacteristics'] = pre_cleaned_df['DataSetCharacteristics'].astype(str)\n",
    "\n",
    "# create a column for each data characteristic value is 1 if true, 0 if false\n",
    "pre_cleaned_df['multivariate_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Multivariate').astype(int)\n",
    "pre_cleaned_df['time_series_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Time-Series').astype(int)\n",
    "pre_cleaned_df['data_generator_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Data-Generator').astype(int)\n",
    "pre_cleaned_df['domain_theory_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Domain-Theory').astype(int)\n",
    "pre_cleaned_df['image_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('image').astype(int)\n",
    "pre_cleaned_df['relational_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Relational').astype(int)\n",
    "pre_cleaned_df['sequential_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Sequential').astype(int)\n",
    "pre_cleaned_df['spatial_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Spatial').astype(int)\n",
    "pre_cleaned_df['univariate_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Univariate').astype(int)\n",
    "pre_cleaned_df['spatio_temporal_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Spatio-temporal').astype(int)\n",
    "pre_cleaned_df['text_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Text').astype(int)\n",
    "pre_cleaned_df['transactional_data'] = pre_cleaned_df['DataSetCharacteristics'].str.contains('Transactional').astype(int)\n",
    "\n",
    "#delete original data set characteristics column\n",
    "del pre_cleaned_df['DataSetCharacteristics']\n",
    "\n",
    "#define function to add values from all data characteristic columns in each row\n",
    "\n",
    "num_characteristics = lambda row: (row.multivariate_data + row.time_series_data + row.data_generator_data +\n",
    "                                  row.domain_theory_data + row.image_data + row.relational_data + row.sequential_data +\n",
    "                                  row.spatial_data + row.univariate_data + row.spatio_temporal_data)\n",
    "\n",
    "#create column to count number of data characteristics and apply lambda\n",
    "pre_cleaned_df['num_data_characteristics'] = pre_cleaned_df.apply(num_characteristics, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column for each attribute characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force attribute characteristics column to string data type\n",
    "pre_cleaned_df['AttributeCharacteristics'] = pre_cleaned_df['AttributeCharacteristics'].astype(str)\n",
    "\n",
    "#ceate a column for each attribute characterstic, value is 1 if true, 0 if false\n",
    "pre_cleaned_df['AttributeCharacteristics'] = pre_cleaned_df['AttributeCharacteristics'].astype(str)\n",
    "pre_cleaned_df['categorical_attributes'] = pre_cleaned_df['AttributeCharacteristics'].str.contains('Categorical').astype(int)\n",
    "pre_cleaned_df['real_attributes'] = pre_cleaned_df['AttributeCharacteristics'].str.contains('Real').astype(int)\n",
    "pre_cleaned_df['integer_attributes'] = pre_cleaned_df['AttributeCharacteristics'].str.contains('Integer').astype(int)\n",
    "pre_cleaned_df['integer_attributes'] = pre_cleaned_df['AttributeCharacteristics'].str.contains('Integer').astype(int)\n",
    "pre_cleaned_df['no_listed_attributes'] = pre_cleaned_df['AttributeCharacteristics'].str.contains('Other').astype(int)\n",
    "\n",
    "#delete original attribute characteristics column\n",
    "del pre_cleaned_df['AttributeCharacteristics']\n",
    "\n",
    "#define function to add values from all attribute characteristic columns in each row\n",
    "num_attribute_types = lambda row: (row.categorical_attributes + row.real_attributes + row.integer_attributes +\n",
    "                                    row.no_listed_attributes)\n",
    "\n",
    "#create column to count number of attribute characteristics and apply lambda\n",
    "pre_cleaned_df['num_attribute_characteristics'] = pre_cleaned_df.apply(num_attribute_types, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column for each Associated Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force associated task column to string data type\n",
    "pre_cleaned_df['AssociatedTasks'] = pre_cleaned_df['AssociatedTasks'].astype(str)\n",
    "\n",
    "#ceate a column for each associated task, value is 1 if true, 0 if false\n",
    "pre_cleaned_df['causal_discover_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Causal-Discovery').astype(int)\n",
    "pre_cleaned_df['classification_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Classification').astype(int)\n",
    "pre_cleaned_df['regression_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Regression').astype(int)\n",
    "pre_cleaned_df['function_learning_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Function-Learning').astype(int)\n",
    "pre_cleaned_df['reccomendation_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Recommendation' or\n",
    "                                                                                       'Recommender-Systems').astype(int)\n",
    "pre_cleaned_df['description_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Description').astype(int)\n",
    "pre_cleaned_df['relational_learning_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Relational-Learning').astype(int)\n",
    "pre_cleaned_df['no_given_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Other').astype(int)\n",
    "pre_cleaned_df['clustering_task'] = pre_cleaned_df['AssociatedTasks'].str.contains('Clustering').astype(int)\n",
    "\n",
    "#delete original associated task column\n",
    "del pre_cleaned_df['AssociatedTasks']\n",
    "\n",
    "#define function to add values from all associated task columns in each row\n",
    "num_associated_tasks = lambda row: (row.causal_discover_task + row.classification_task + row.regression_task +\n",
    "                                    row.function_learning_task + row.reccomendation_task + \n",
    "                                     row.description_task +  row.relational_learning_task)\n",
    "\n",
    "#create column to count number of associated tasks and apply lambda\n",
    "pre_cleaned_df['num_associated_tasks'] = pre_cleaned_df.apply(num_attribute_types, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date donated to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_cleaned_df['DateDonated'] = pd.to_datetime(pre_cleaned_df['DateDonated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export clean data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pre_cleaned_df\n",
    "clean_data.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all remaining NaNs for the squeekiest clean data and export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest_data = clean_data.dropna()\n",
    "cleanest_data.to_csv('cleanest_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
